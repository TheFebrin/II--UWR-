{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "from collections import OrderedDict \n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read data and split in train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dane_pozytywistyczne/korpus_orzeszkowej.txt', encoding='UTF-8') as f:\n",
    "    orzeszkowa = [x for x in f.readlines() if len(x) > 1]\n",
    "    \n",
    "with open('dane_pozytywistyczne/korpus_prusa.txt', encoding='UTF-8') as f:\n",
    "    prus = [x for x in f.readlines() if len(x) > 1]\n",
    "    \n",
    "with open('dane_pozytywistyczne/korpus_sienkiewicza.txt', encoding='UTF-8') as f:\n",
    "    sienkiewicz = [x for x in f.readlines() if len(x) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6291, 8323, 2615)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orzeszkowa), len(prus), len(sienkiewicz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_O, test_O = train_test_split(orzeszkowa, test_size=0.33, random_state=42)\n",
    "train_P, test_P = train_test_split(prus, test_size=0.33, random_state=42)\n",
    "train_S, test_S = train_test_split(sienkiewicz, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create normalized lookup tables for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(line: str) -> list:\n",
    "    return re.sub(r'[^\\w\\s]', '', line).strip().lower().split()\n",
    "#     return re.sub(r'[\\W+]', '', line).strip().lower()\n",
    "\n",
    "def preprocess(train: list) -> list:\n",
    "    return list(itertools.chain.from_iterable([regex(line) for line in train]))\n",
    "#     return ''.join([regex(line) for line in train if len(line) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_in_one_string = preprocess(train=train_O) + preprocess(train=train_P) + preprocess(train=train_S)\n",
    "all_letters = set(all_text_in_one_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 s, sys: 59 µs, total: 8 s\n",
      "Wall time: 8.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_O_letters_occurencies = Counter(preprocess(train=train_O))\n",
    "train_P_letters_occurencies = Counter(preprocess(train=train_P))\n",
    "train_S_letters_occurencies = Counter(preprocess(train=train_S))\n",
    "\n",
    "train_O_letters_occurencies = {k: v / sum(train_O_letters_occurencies.values()) \n",
    "                                for k, v in train_O_letters_occurencies.items()}\n",
    "\n",
    "train_P_letters_occurencies = {k: v / sum(train_P_letters_occurencies.values()) \n",
    "                                for k, v in train_P_letters_occurencies.items()}\n",
    "\n",
    "train_S_letters_occurencies = {k: v / sum(train_S_letters_occurencies.values()) \n",
    "                                for k, v in train_S_letters_occurencies.items()}\n",
    "\n",
    "languages = [\n",
    "    train_O_letters_occurencies,\n",
    "    train_P_letters_occurencies,\n",
    "    train_S_letters_occurencies\n",
    "]\n",
    "\n",
    "names = ['Orzeszkowa', 'Prus', 'Sienkiewicz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(\n",
    "    sentence: str, \n",
    "    languages: list = languages, \n",
    "    names: list = names,\n",
    "    normalize: bool = True,\n",
    "    UNK: float = 1e-5\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns the most probable language of a sentence\n",
    "    \n",
    "    :param languages: List of dictionaries\n",
    "    :param names: Names of those languages\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence = regex(line=sentence)\n",
    "\n",
    "    log_probs = {}\n",
    "    Z = 0.0\n",
    "    for i, lang in enumerate(languages):\n",
    "        P_DC = np.sum(np.array(([np.log(lang[x]) if x in lang else np.log(UNK) for x in sentence])))\n",
    "        if normalize:\n",
    "            P_DC = np.exp(P_DC)\n",
    "        log_probs[names[i]] = P_DC * (1 / len(languages))\n",
    "        Z += log_probs[names[i]]\n",
    "    \n",
    "    if normalize:\n",
    "        for x in log_probs:\n",
    "            log_probs[x] /= (Z + 1e-18)\n",
    "        \n",
    "    probs = OrderedDict(reversed(sorted(log_probs.items(), key=itemgetter(1))))\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Sienkiewicz', 0.9430753675093664),\n",
       "             ('Prus', 0.026027607397559212),\n",
       "             ('Orzeszkowa', 0.02199449379231031)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes(\n",
    "    sentence='W dwa miesiące potem Marysia', \n",
    "    languages=languages, \n",
    "    names=names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validate accuracy\n",
    "\n",
    "NB: Using only letters accuracy was 24%, 47%, 50% for Orzeszkowa, Prus and Sienkiewicz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.60086663456909"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_O = [next(iter(naive_bayes(x, normalize=False))) for x in test_O]\n",
    "accuracy_O = classify_O.count('Orzeszkowa') / len(classify_O)\n",
    "accuracy_O * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.70840917364397"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_P = [next(iter(naive_bayes(x, normalize=False))) for x in test_P]\n",
    "accuracy_P = classify_P.count('Prus') / len(classify_P)\n",
    "accuracy_P * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.95365005793744"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_S = [next(iter(naive_bayes(x, normalize=False))) for x in test_S]\n",
    "accuracy_S = classify_S.count('Sienkiewicz') / len(classify_S)\n",
    "accuracy_S * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1591,  321,  165],\n",
       "       [ 197, 2272,  278],\n",
       "       [  52,  121,  690]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix:')\n",
    "\n",
    "CM = confusion_matrix(\n",
    "    ['Orzeszkowa'] * len(classify_O) + ['Prus'] * len(classify_P) + ['Sienkiewicz'] * len(classify_S), \n",
    "    classify_O + classify_P + classify_S\n",
    ")\n",
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix in percentages:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[76, 15,  7],\n",
       "       [ 7, 82, 10],\n",
       "       [ 6, 14, 79]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix in percentages:')\n",
    "\n",
    "(CM / CM.sum(axis=1)[:, np.newaxis] * 100).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: \n",
      "80.05978547564621\n"
     ]
    }
   ],
   "source": [
    "print('Total accuracy: ')\n",
    "\n",
    "print(np.diag(CM).sum() / CM.sum() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate on another tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_O, valid_P, valid_S = [], [], []\n",
    "\n",
    "path = 'dane_pozytywistyczne/testy1'\n",
    "for file_name in os.listdir(path):\n",
    "    if file_name.find('orzeszkowej') != -1:\n",
    "        with open(path + '/' + file_name, encoding='UTF-8') as f:\n",
    "            valid_O.append([x for x in f.readlines() if len(x) > 1])\n",
    "    \n",
    "    if file_name.find('prus') != -1:\n",
    "        with open(path + '/' + file_name, encoding='UTF-8') as f:\n",
    "            valid_P.append([x for x in f.readlines() if len(x) > 1])\n",
    "    \n",
    "    if file_name.find('sienkiewicz') != -1:\n",
    "        with open(path + '/' + file_name, encoding='UTF-8') as f:\n",
    "            valid_S.append([x for x in f.readlines() if len(x) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_O_sentences = [\n",
    "    sentence \n",
    "    for text in valid_O \n",
    "        for line in text \n",
    "            for sentence in line.split('.') \n",
    "                if len(sentence) > 1\n",
    "]\n",
    "\n",
    "valid_P_sentences = [\n",
    "    sentence \n",
    "    for text in valid_P \n",
    "        for line in text \n",
    "            for sentence in line.split('.') \n",
    "                if len(sentence) > 1\n",
    "]\n",
    "\n",
    "valid_S_sentences = [\n",
    "    sentence \n",
    "    for text in valid_S \n",
    "        for line in text \n",
    "            for sentence in line.split('.') \n",
    "                if len(sentence) > 1\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With normalization, every text divided on sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orzeszkowa: 47.15%\n",
      "Prus: 73.07%\n",
      "Sienkiewicz: 44.90%\n",
      "\n",
      "=================================\n",
      "\n",
      "Confusion matrix in percentages:\n",
      "[[47 22 30]\n",
      " [ 7 73 19]\n",
      " [12 42 44]]\n",
      "\n",
      "=================================\n",
      "\n",
      "Total accuracy: \n",
      "56.057737813535255\n"
     ]
    }
   ],
   "source": [
    "UNK=1e-5\n",
    "\n",
    "classify_valid_O = [next(iter(naive_bayes(sentence, normalize=True, UNK=UNK)))\n",
    "                        for sentence in valid_O_sentences]\n",
    "accuracy_valid_O = classify_valid_O.count('Orzeszkowa') / len(classify_valid_O)\n",
    "print(f'Orzeszkowa: {accuracy_valid_O * 100:.2f}%')\n",
    "\n",
    "\n",
    "classify_valid_P = [next(iter(naive_bayes(sentence, normalize=True, UNK=UNK)))\n",
    "                        for sentence in valid_P_sentences]\n",
    "accuracy_valid_P = classify_valid_P.count('Prus') / len(classify_valid_P)\n",
    "print(f'Prus: {accuracy_valid_P * 100:.2f}%')\n",
    "\n",
    "\n",
    "classify_valid_S = [next(iter(naive_bayes(sentence, normalize=True, UNK=UNK)))\n",
    "                        for sentence in valid_S_sentences]\n",
    "accuracy_valid_S = classify_valid_S.count('Sienkiewicz') / len(classify_valid_S)\n",
    "accuracy_valid_S * 100\n",
    "print(f'Sienkiewicz: {accuracy_valid_S * 100:.2f}%')\n",
    "\n",
    "CM = confusion_matrix(\n",
    "    ['Orzeszkowa'] * len(classify_valid_O) + ['Prus'] * len(classify_valid_P) + ['Sienkiewicz'] * len(classify_valid_S), \n",
    "    classify_valid_O + classify_valid_P + classify_valid_S\n",
    ")\n",
    "\n",
    "\n",
    "print('\\n=================================\\n')\n",
    "print('Confusion matrix in percentages:')\n",
    "print((CM / CM.sum(axis=1)[:, np.newaxis] * 100).astype(np.int))\n",
    "\n",
    "print('\\n=================================\\n')\n",
    "print('Total accuracy: ')\n",
    "print(np.diag(CM).sum() / CM.sum() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without normalization, every text as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orzeszkowa: 66.67%\n",
      "Prus: 95.24%\n",
      "Sienkiewicz: 51.85%\n",
      "\n",
      "=================================\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 8  0  4]\n",
      " [ 0 20  1]\n",
      " [ 0 13 14]]\n",
      "\n",
      "=================================\n",
      "\n",
      "Confusion matrix in percentages:\n",
      "[[66  0 33]\n",
      " [ 0 95  4]\n",
      " [ 0 48 51]]\n",
      "\n",
      "=================================\n",
      "\n",
      "Total accuracy: \n",
      "70.0\n"
     ]
    }
   ],
   "source": [
    "UNK=1e-5\n",
    "\n",
    "classify_valid_O = [next(iter(naive_bayes(' '.join(preprocess(test)), normalize=False, UNK=UNK))) \n",
    "                        for test in valid_O]\n",
    "accuracy_valid_O = classify_valid_O.count('Orzeszkowa') / len(classify_valid_O)\n",
    "print(f'Orzeszkowa: {accuracy_valid_O * 100:.2f}%')\n",
    "\n",
    "classify_valid_P = [next(iter(naive_bayes(' '.join(preprocess(test)), normalize=False, UNK=UNK))) \n",
    "                        for test in valid_P]\n",
    "accuracy_valid_P = classify_valid_P.count('Prus') / len(classify_valid_P)\n",
    "print(f'Prus: {accuracy_valid_P * 100:.2f}%')\n",
    "\n",
    "classify_valid_S = [next(iter(naive_bayes(' '.join(preprocess(test)), normalize=False, UNK=UNK))) \n",
    "                        for test in valid_S]\n",
    "accuracy_valid_S = classify_valid_S.count('Sienkiewicz') / len(classify_valid_S)\n",
    "print(f'Sienkiewicz: {accuracy_valid_S * 100:.2f}%')\n",
    "\n",
    "print('\\n=================================\\n')\n",
    "print('Confusion matrix:')\n",
    "CM = confusion_matrix(\n",
    "    ['Orzeszkowa'] * len(classify_valid_O) + ['Prus'] * len(classify_valid_P) + ['Sienkiewicz'] * len(classify_valid_S), \n",
    "    classify_valid_O + classify_valid_P + classify_valid_S\n",
    ")\n",
    "print(CM)\n",
    "\n",
    "print('\\n=================================\\n')\n",
    "print('Confusion matrix in percentages:')\n",
    "print((CM / CM.sum(axis=1)[:, np.newaxis] * 100).astype(np.int))\n",
    "\n",
    "print('\\n=================================\\n')\n",
    "print('Total accuracy: ')\n",
    "print(np.diag(CM).sum() / CM.sum() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
